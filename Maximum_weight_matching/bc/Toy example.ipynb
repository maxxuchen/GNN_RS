{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c84ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import gzip\n",
    "import pickle\n",
    "import pathlib\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960de739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils.convert import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f176ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_FEATURE_NUM = 2\n",
    "\n",
    "class GraphConvolution(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.project = torch.nn.Linear(NODE_FEATURE_NUM, 32)\n",
    "        self.conv1 = GCNConv(32, 32)\n",
    "        self.conv2 = GCNConv(32, 32)\n",
    "        self.conv3 = GCNConv(32, 32)\n",
    "        self.conv4 = GCNConv(32, 32)\n",
    "        self.conv5 = GCNConv(32, 32)\n",
    "        self.conv6 = GCNConv(32, 32)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32 * 2, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x.float(), data.edge_index, data.weight.float()\n",
    "\n",
    "        x = self.project(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv5(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv6(x, edge_index, edge_weight)\n",
    "\n",
    "        # edge regression\n",
    "        batch_size = len(data.edges)\n",
    "        total_edges = sum(len(data.edges[u]) for u in range(batch_size))\n",
    "        output = torch.zeros(total_edges)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            _edges = data.edges[i]  # edge set of the i-th graph\n",
    "            _nodes = data.nodes[i]  # node set of the i-th graph\n",
    "            num_edge = len(_edges)\n",
    "            num_node = len(_nodes)\n",
    "\n",
    "            # the total number of nodes before i-th graph\n",
    "            nodes_before = sum(len(data.nodes[u]) for u in range(i))\n",
    "            edges_before = sum(len(data.edges[u]) for u in range(i))\n",
    "\n",
    "            # get the node feature x of i-th graph\n",
    "            _x = x[nodes_before: nodes_before + num_node]\n",
    "\n",
    "            score = torch.zeros(num_edge)\n",
    "            for j in range(num_edge):\n",
    "                v1 = _edges[j][0]\n",
    "                v2 = _edges[j][1]\n",
    "                v1_index = _nodes.index(v1)  # get index of node\n",
    "                v2_index = _nodes.index(v2)\n",
    "                score[j] = self.seq(torch.cat((_x[v1_index, :], _x[v2_index, :])))\n",
    "            score = F.softmax(score, dim=0)\n",
    "            output[edges_before: edges_before + num_edge] = score\n",
    "\n",
    "        return output\n",
    "\n",
    "    def eval(self, data):\n",
    "        torch.set_grad_enabled(False)\n",
    "        x, edge_index, edge_weight = data.x.float(), data.edge_index, data.weight.float()\n",
    "\n",
    "        x = self.project(x)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "\n",
    "        # edge regression\n",
    "        batch_size = len(data.edges)\n",
    "        total_edges = sum(len(data.edges[u]) for u in range(batch_size))\n",
    "\n",
    "        _edges = data.edges\n",
    "        _nodes = data.nodes\n",
    "        num_edge = len(_edges)\n",
    "        num_node = len(_nodes)\n",
    "\n",
    "        # get the node feature x of i-th graph\n",
    "        _x = x\n",
    "        score = torch.zeros(num_edge)\n",
    "        for j in range(num_edge):\n",
    "            v1 = _edges[j][0]\n",
    "            v2 = _edges[j][1]\n",
    "            v1_index = _nodes.index(v1)  # get index of node\n",
    "            v2_index = _nodes.index(v2)\n",
    "            score[j] = self.seq(torch.cat((_x[v1_index, :], _x[v2_index, :])))\n",
    "        score = F.softmax(score, dim=0)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e072b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change networkx graph into GCN input format\n",
    "def networkx2torch(graph):\n",
    "    data = from_networkx(graph)\n",
    "    data.edges = [edge for edge in graph.edges]\n",
    "    data.nodes = [node for node in graph.nodes]\n",
    "    data.x = data.pos\n",
    "\n",
    "    return data\n",
    "\n",
    "def Guided_Search(policy, graph):\n",
    "    '''\n",
    "    :param policy: GCN model\n",
    "    :param graph: networkx graph\n",
    "    :return: a match\n",
    "    '''\n",
    "    edges = [edge for edge in graph.edges]\n",
    "    selection = np.zeros(len(edges))\n",
    "    done = False\n",
    "\n",
    "    temp_graph = graph.copy()\n",
    "    while not done:\n",
    "        # choose the edge with the highest score\n",
    "        GCN_input = networkx2torch(temp_graph)\n",
    "        temp_edges = GCN_input.edges  # list\n",
    "        score = policy(GCN_input).detach().numpy()  # tensor to numpy array\n",
    "        edge_chosen = temp_edges[np.argmax(score)]\n",
    "        selection[edges.index(edge_chosen)] = 1\n",
    "\n",
    "        # delete edges and nodes\n",
    "        for node_chosen in edge_chosen:\n",
    "            # Removes the node_chosen and all adjacent edges\n",
    "            temp_graph.remove_node(node_chosen)\n",
    "\n",
    "        # check whether done\n",
    "        if len(temp_graph.edges) == 0:\n",
    "            done = True\n",
    "\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d5ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imitation learning target\n",
    "def get_target(MWM, G):\n",
    "    edges = [edge for edge in G.edges]\n",
    "    selection = np.zeros(len(edges))\n",
    "    for i in range(len(edges)):\n",
    "        if edges[i] not in MWM:\n",
    "            selection[i] = 0\n",
    "        else:\n",
    "            selection[i] = 1\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcd1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(torch_geometric.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class implementing the basic methods to read samples from a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_files : list\n",
    "        List containing the path to the sample files.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_files):\n",
    "        super().__init__(root=None, transform=None, pre_transform=None)\n",
    "        self.sample_files = sample_files\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.sample_files)\n",
    "\n",
    "    def get(self, index):\n",
    "        \"\"\"\n",
    "        Reads and returns sample at position <index> of the dataset.\n",
    "\n",
    "        \"\"\"\n",
    "        with gzip.open(self.sample_files[index], 'rb') as f:\n",
    "            sample = pickle.load(f)\n",
    "\n",
    "        graph = sample['graph']\n",
    "        MWM = sample['MWM']\n",
    "\n",
    "        # change networkx graph into GCN input\n",
    "        data = networkx2torch(graph)\n",
    "\n",
    "        # add label\n",
    "        mwm = get_target(MWM, graph)  # get binary selection matrix\n",
    "        data.mwm = mwm\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e9c903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(policy, data_loader, device, optimizer=None):\n",
    "    mean_loss = 0\n",
    "    n_samples_processed = 0\n",
    "\n",
    "    with torch.set_grad_enabled(optimizer is not None):\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = policy(batch)\n",
    "\n",
    "            # get target\n",
    "            batch_size = len(batch.edges)\n",
    "            total_edges = sum(len(batch.edges[u]) for u in range(batch_size))\n",
    "            target = torch.zeros(total_edges)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                num_edge = len(batch.edges[i])  # the total number of nodes before i-th graph\n",
    "                edges_before = sum(len(batch.edges[u]) for u in range(i))\n",
    "                target[edges_before: edges_before + num_edge] = torch.from_numpy(batch.mwm[i])\n",
    "\n",
    "            # calculate cross entropy\n",
    "            target = target.to(device)\n",
    "            cross_entropy_loss = F.binary_cross_entropy(output, target)\n",
    "\n",
    "            # if an optimizer is provided, update parameters\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "                cross_entropy_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            mean_loss += cross_entropy_loss.item() * data_loader.batch_size\n",
    "            n_samples_processed += data_loader.batch_size\n",
    "\n",
    "    mean_loss /= n_samples_processed\n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7cad5c",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62ee9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/zwt/MWM/bc'\n",
    "train_files_path = os.path.join(DIR, 'samples/train/sample_*.pkl')\n",
    "valid_files_path = os.path.join(DIR, 'samples/valid/sample_*.pkl')\n",
    "trained_model_dir = os.path.join(DIR, 'trained_models')\n",
    "\n",
    "train_files = glob.glob(train_files_path)[:100]\n",
    "valid_files = glob.glob(valid_files_path)[:20]\n",
    "device = f\"cuda:0\"\n",
    "EPOCH_SAMPLE_NUM = 100\n",
    "batch_size = 5\n",
    "valid_batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af98aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = GraphDataset(valid_files)\n",
    "valid_loader = torch_geometric.data.DataLoader(valid_data, valid_batch_size, shuffle=False)\n",
    "\n",
    "policy = GraphConvolution().to(device)\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb7b0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node2edge(data):\n",
    "    \"\"\"\n",
    "    :param data: torch_geometric.data.Data\n",
    "        data.x: node feature\n",
    "        data.edges: edge index set\n",
    "        data.nodes: node index set\n",
    "    :return:\n",
    "        output: torch [total_edges, 2 * NODE_FEATURE_NUM]\n",
    "            the edge features\n",
    "    \"\"\"\n",
    "    # change node feature into edge feature\n",
    "    batch_size = len(data.edges)\n",
    "    total_edges = sum(len(data.edges[u]) for u in range(batch_size))\n",
    "    output = torch.zeros(total_edges, 2 * NODE_FEATURE_NUM)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        _edges = data.edges[i]  # edge set of the i-th graph\n",
    "        _nodes = data.nodes[i]  # node set of the i-th graph\n",
    "        num_edge = len(_edges)\n",
    "        num_node = len(_nodes)\n",
    "\n",
    "        # the total number of nodes before i-th graph\n",
    "        nodes_before = sum(len(data.nodes[u]) for u in range(i))\n",
    "        edges_before = sum(len(data.edges[u]) for u in range(i))\n",
    "\n",
    "        # get the node feature x of i-th graph\n",
    "        _x = data.x[nodes_before: nodes_before + num_node]\n",
    "\n",
    "        for j in range(num_edge):\n",
    "            v1 = _edges[j][0]\n",
    "            v2 = _edges[j][1]\n",
    "            v1_index = _nodes.index(v1)  # get index of node\n",
    "            v2_index = _nodes.index(v2)\n",
    "            output[edges_before + j, :] = torch.cat((_x[v1_index, :], _x[v2_index, :]))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed71a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([328, 4])\n",
      "torch.Size([322, 4])\n",
      "torch.Size([323, 4])\n",
      "torch.Size([340, 4])\n",
      "torch.Size([306, 4])\n",
      "torch.Size([343, 4])\n",
      "torch.Size([305, 4])\n",
      "torch.Size([323, 4])\n",
      "torch.Size([337, 4])\n",
      "torch.Size([309, 4])\n",
      "torch.Size([318, 4])\n",
      "torch.Size([305, 4])\n",
      "torch.Size([337, 4])\n",
      "torch.Size([352, 4])\n",
      "torch.Size([337, 4])\n",
      "torch.Size([314, 4])\n",
      "torch.Size([333, 4])\n",
      "torch.Size([301, 4])\n",
      "torch.Size([309, 4])\n",
      "torch.Size([340, 4])\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "epoch_train_files = rng.choice(train_files, int(np.floor(EPOCH_SAMPLE_NUM / batch_size)) * batch_size,\n",
    "                               replace=True)\n",
    "train_data = GraphDataset(epoch_train_files)\n",
    "train_loader = torch_geometric.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    batch = batch.to(device)\n",
    "    output = node2edge(batch)\n",
    "    print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455994eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.RandomState(0)\n",
    "\n",
    "# for epoch in range(10000):\n",
    "#     # train\n",
    "#     epoch_train_files = rng.choice(train_files, int(np.floor(EPOCH_SAMPLE_NUM / batch_size)) * batch_size,\n",
    "#                                    replace=True)\n",
    "#     train_data = GraphDataset(epoch_train_files)\n",
    "#     train_loader = torch_geometric.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "#     train_loss = process(policy, train_loader, device, optimizer)\n",
    "\n",
    "#     # validate\n",
    "#     valid_loss = process(policy, valid_loader, device, None)\n",
    "    \n",
    "#     if epoch%100==0:\n",
    "#         print(f'Epoch: {epoch}, Train Loss: {train_loss:0.4f}, Valid Loss: {valid_loss:0.4f}. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84390ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sh",
   "language": "python",
   "name": "ml4sh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
